{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>series</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>segmentation_id</th>\n",
       "      <th>image_view</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>lw_x_points</th>\n",
       "      <th>lw_y_points</th>\n",
       "      <th>mammography_type</th>\n",
       "      <th>mammography_nodule</th>\n",
       "      <th>mammography_calcification</th>\n",
       "      <th>mammography_microcalcification</th>\n",
       "      <th>mammography_axillary_adenopathy</th>\n",
       "      <th>mammography_architectural_distortion</th>\n",
       "      <th>mammography_stroma_distortion</th>\n",
       "      <th>age</th>\n",
       "      <th>density</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_179/study_185/img_179_185_1_LCC.tif</td>\n",
       "      <td>12 13 14 14 14 14 14 15 16 17 18 18 19 20 21 ...</td>\n",
       "      <td>603 602 601 600 599 598 597 596 595 594 593 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>patient_179/study_185/img_179_185_1_LO.tif</td>\n",
       "      <td>92 93 94 95 96 97 98 99 100 101 102 103 104 1...</td>\n",
       "      <td>835 835 834 834 833 833 833 833 833 833 833 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_182/study_188/img_182_188_1_LCC.tif</td>\n",
       "      <td>424 425 426 427 428 429 430 431 432 433 434 4...</td>\n",
       "      <td>278 278 278 278 277 276 275 274 273 273 273 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>patient_182/study_188/img_182_188_1_LO.tif</td>\n",
       "      <td>517 518 519 520 521 522 523 524 525 526 527 5...</td>\n",
       "      <td>413 413 413 412 411 410 410 410 410 410 410 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_190/study_196/img_190_196_1_LCC.tif</td>\n",
       "      <td>182 183 184 185 186 187 188 189 190 191 192 1...</td>\n",
       "      <td>520 520 520 520 520 520 519 519 519 519 519 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>596</td>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "      <td>621</td>\n",
       "      <td>1424</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_596/study_650/img_596_650_1_LCC.tif</td>\n",
       "      <td>314 313 312 311 310 309 308 307 306 305 304 3...</td>\n",
       "      <td>858 858 858 858 858 858 858 858 858 859 859 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>615</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>1453</td>\n",
       "      <td>4</td>\n",
       "      <td>patient_615/study_672/img_615_672_1_LO.tif</td>\n",
       "      <td>80 79 79 79 79 78 77 76 75 75 74 73 72 71 71 ...</td>\n",
       "      <td>627 628 629 630 631 632 633 634 635 636 637 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>615</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>1454</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_615/study_672/img_615_672_1_LCC.tif</td>\n",
       "      <td>71 70 70 70 70 69 68 67 67 67 67 67 67 66 65 ...</td>\n",
       "      <td>580 581 582 583 584 585 586 587 588 589 590 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>681</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>1056</td>\n",
       "      <td>1494</td>\n",
       "      <td>2</td>\n",
       "      <td>patient_681/study_740/img_681_740_1_LCC.tif</td>\n",
       "      <td>206 205 204 203 203 202 201 200 199 198 197 1...</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>681</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>1056</td>\n",
       "      <td>1495</td>\n",
       "      <td>4</td>\n",
       "      <td>patient_681/study_740/img_681_740_1_LO.tif</td>\n",
       "      <td>323 324 325 326 327 328 329 330 331 332 333 3...</td>\n",
       "      <td>575 575 575 575 575 575 575 575 575 574 574 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>Malign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  study_id  series  lesion_id  segmentation_id  image_view  \\\n",
       "0           179       185       1        185                3           2   \n",
       "1           179       185       1        185                4           4   \n",
       "2           182       188       1        188                7           2   \n",
       "3           182       188       1        188                8           4   \n",
       "4           190       196       1        196               13           2   \n",
       "..          ...       ...     ...        ...              ...         ...   \n",
       "357         596       650       1        621             1424           2   \n",
       "358         615       672       1        631             1453           4   \n",
       "359         615       672       1        631             1454           2   \n",
       "360         681       740       1       1056             1494           2   \n",
       "361         681       740       1       1056             1495           4   \n",
       "\n",
       "                                   image_filename  \\\n",
       "0     patient_179/study_185/img_179_185_1_LCC.tif   \n",
       "1      patient_179/study_185/img_179_185_1_LO.tif   \n",
       "2     patient_182/study_188/img_182_188_1_LCC.tif   \n",
       "3      patient_182/study_188/img_182_188_1_LO.tif   \n",
       "4     patient_190/study_196/img_190_196_1_LCC.tif   \n",
       "..                                            ...   \n",
       "357   patient_596/study_650/img_596_650_1_LCC.tif   \n",
       "358    patient_615/study_672/img_615_672_1_LO.tif   \n",
       "359   patient_615/study_672/img_615_672_1_LCC.tif   \n",
       "360   patient_681/study_740/img_681_740_1_LCC.tif   \n",
       "361    patient_681/study_740/img_681_740_1_LO.tif   \n",
       "\n",
       "                                           lw_x_points  \\\n",
       "0     12 13 14 14 14 14 14 15 16 17 18 18 19 20 21 ...   \n",
       "1     92 93 94 95 96 97 98 99 100 101 102 103 104 1...   \n",
       "2     424 425 426 427 428 429 430 431 432 433 434 4...   \n",
       "3     517 518 519 520 521 522 523 524 525 526 527 5...   \n",
       "4     182 183 184 185 186 187 188 189 190 191 192 1...   \n",
       "..                                                 ...   \n",
       "357   314 313 312 311 310 309 308 307 306 305 304 3...   \n",
       "358   80 79 79 79 79 78 77 76 75 75 74 73 72 71 71 ...   \n",
       "359   71 70 70 70 70 69 68 67 67 67 67 67 67 66 65 ...   \n",
       "360   206 205 204 203 203 202 201 200 199 198 197 1...   \n",
       "361   323 324 325 326 327 328 329 330 331 332 333 3...   \n",
       "\n",
       "                                           lw_y_points  mammography_type  \\\n",
       "0     603 602 601 600 599 598 597 596 595 594 593 5...                 1   \n",
       "1     835 835 834 834 833 833 833 833 833 833 833 8...                 1   \n",
       "2     278 278 278 278 277 276 275 274 273 273 273 2...                 1   \n",
       "3     413 413 413 412 411 410 410 410 410 410 410 4...                 1   \n",
       "4     520 520 520 520 520 520 519 519 519 519 519 5...                 1   \n",
       "..                                                 ...               ...   \n",
       "357   858 858 858 858 858 858 858 858 858 859 859 8...                 1   \n",
       "358   627 628 629 630 631 632 633 634 635 636 637 6...                 1   \n",
       "359   580 581 582 583 584 585 586 587 588 589 590 5...                 1   \n",
       "360   465 466 467 468 469 470 471 472 473 474 475 4...                 1   \n",
       "361   575 575 575 575 575 575 575 575 575 574 574 5...                 1   \n",
       "\n",
       "     mammography_nodule  mammography_calcification  \\\n",
       "0                     0                          0   \n",
       "1                     0                          0   \n",
       "2                     1                          0   \n",
       "3                     1                          0   \n",
       "4                     1                          0   \n",
       "..                  ...                        ...   \n",
       "357                   1                          0   \n",
       "358                   1                          0   \n",
       "359                   1                          0   \n",
       "360                   1                          0   \n",
       "361                   1                          0   \n",
       "\n",
       "     mammography_microcalcification  mammography_axillary_adenopathy  \\\n",
       "0                                 1                                0   \n",
       "1                                 1                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "..                              ...                              ...   \n",
       "357                               0                                0   \n",
       "358                               1                                0   \n",
       "359                               1                                0   \n",
       "360                               0                                0   \n",
       "361                               0                                0   \n",
       "\n",
       "     mammography_architectural_distortion  mammography_stroma_distortion  age  \\\n",
       "0                                       0                              1   53   \n",
       "1                                       0                              1   53   \n",
       "2                                       0                              0   68   \n",
       "3                                       0                              0   68   \n",
       "4                                       0                              0   57   \n",
       "..                                    ...                            ...  ...   \n",
       "357                                     0                              0   59   \n",
       "358                                     0                              0   71   \n",
       "359                                     0                              0   71   \n",
       "360                                     0                              0   51   \n",
       "361                                     0                              0   51   \n",
       "\n",
       "    density classification  \n",
       "0         1         Malign  \n",
       "1         1         Malign  \n",
       "2         1         Malign  \n",
       "3         1         Malign  \n",
       "4         3         Benign  \n",
       "..      ...            ...  \n",
       "357       1         Malign  \n",
       "358       3         Malign  \n",
       "359       3         Malign  \n",
       "360       3         Malign  \n",
       "361       3         Malign  \n",
       "\n",
       "[362 rows x 19 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Asumiendo que tu archivo se llama 'classification.xlsx'\n",
    "df = pd.read_csv('c:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal/BCDR-F01_dataset/BCDR-F01_dataset/bcdr_f01_outlines.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando BCDR-D01_dataset usando C:\\Users\\Matias\\OneDrive\\Escritorio\\Tesis\\Data Portugal\\BCDR-D01_dataset\\bcdr_d01_outlines.csv\n",
      "Procesando BCDR-F01_dataset usando C:\\Users\\Matias\\OneDrive\\Escritorio\\Tesis\\Data Portugal\\BCDR-F01_dataset\\bcdr_f01_outlines.csv\n",
      "Procesando BCDR-F02_dataset usando C:\\Users\\Matias\\OneDrive\\Escritorio\\Tesis\\Data Portugal\\BCDR-F02_dataset\\bcdr_f02_outlines.csv\n",
      "Procesando BCDR-F03_dataset usando C:\\Users\\Matias\\OneDrive\\Escritorio\\Tesis\\Data Portugal\\BCDR-F03_dataset\\bcdr_f03_outlines.csv\n",
      "Found 1293 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def organizar_imagenes(patient_dir, organized_dir, csv_file_path, pacientes_procesados):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    if not os.path.exists(organized_dir):\n",
    "        os.makedirs(organized_dir)\n",
    "\n",
    "    for patient_folder in os.listdir(patient_dir):\n",
    "        patient_id = patient_folder.split('_')[1]\n",
    "\n",
    "        if patient_id in pacientes_procesados:\n",
    "            continue\n",
    "\n",
    "        pacientes_procesados.add(patient_id)\n",
    "        try:\n",
    "            classification = df[df['patient_id'] == int(patient_id)]['classification'].values[0].strip().lower()\n",
    "        except IndexError:\n",
    "            print(f\"No se encontró clasificación para el paciente {patient_id}\")\n",
    "            continue\n",
    "\n",
    "        patient_path = os.path.join(patient_dir, patient_folder)\n",
    "        \n",
    "        for study_folder in os.listdir(patient_path):\n",
    "            study_path = os.path.join(patient_path, study_folder)\n",
    "            \n",
    "            for image_file in os.listdir(study_path):\n",
    "                new_image_name = f\"{patient_id}_{classification}_{image_file}\"\n",
    "                destination_path = os.path.join(organized_dir, new_image_name)\n",
    "                \n",
    "                shutil.copy(os.path.join(study_path, image_file), destination_path)\n",
    "\n",
    "def convertir_tif_a_jpg(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".tif\"):\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = Image.open(img_path)\n",
    "                output_path = os.path.join(output_dir, os.path.basename(file).replace(\".tif\", \".jpg\"))\n",
    "                img.save(output_path, \"JPEG\")\n",
    "\n",
    "def organizar_imagenes_por_clase(base_dir):\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"El directorio {base_dir} no existe.\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(base_dir) if os.path.isfile(os.path.join(base_dir, f))]\n",
    "    \n",
    "    for file in files:\n",
    "        if \"_\" in file and (file.endswith('.jpg') or file.endswith('.png')):\n",
    "            parts = file.split('_')\n",
    "            if len(parts) > 2:\n",
    "                # Elimina los espacios en blanco y convierte el nombre de la clase a minúsculas\n",
    "                class_name = parts[1].strip().lower()\n",
    "                \n",
    "                class_dir = os.path.join(base_dir, class_name)\n",
    "                if not os.path.exists(class_dir):\n",
    "                    os.makedirs(class_dir)\n",
    "                \n",
    "                src_path = os.path.join(base_dir, file)\n",
    "                dst_path = os.path.join(class_dir, file)\n",
    "                shutil.move(src_path, dst_path)\n",
    "            else:\n",
    "                print(f\"No se puede determinar la clase para el archivo: {file}\")\n",
    "\n",
    "def crear_y_normalizar_dataset(output_dir):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        output_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=(256, 256),\n",
    "        batch_size=32)\n",
    "\n",
    "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "    normalized_ds = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    return normalized_ds\n",
    "\n",
    "def procesar_datasets(ruta_carpeta_base, organized_dir):\n",
    "    ruta_carpeta_base = Path(ruta_carpeta_base)\n",
    "    pacientes_procesados = set()\n",
    "\n",
    "    for dataset_dir in ruta_carpeta_base.iterdir():\n",
    "        if dataset_dir.is_dir() and \"BCDR\" in dataset_dir.name and \"bcdr_dn01\" not in dataset_dir.name.lower():\n",
    "            patient_dir = dataset_dir / 'patients'\n",
    "            csv_file_name = f\"{dataset_dir.name.replace('-', '_').lower().replace('_dataset', '')}_outlines.csv\"\n",
    "            csv_file_path = dataset_dir / csv_file_name\n",
    "            print(f\"Procesando {dataset_dir.name} usando {csv_file_path}\")\n",
    "            organizar_imagenes(patient_dir, organized_dir, csv_file_path, pacientes_procesados)\n",
    "\n",
    "# Configuraciones iniciales\n",
    "ruta_carpeta_base = 'C:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal'\n",
    "organized_dir = 'C:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal/organized_images'\n",
    "output_dir = 'C:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal/converted_images'\n",
    "\n",
    "# Ejecutar el proceso completo\n",
    "procesar_datasets(ruta_carpeta_base, organized_dir)\n",
    "convertir_tif_a_jpg(organized_dir, output_dir)\n",
    "organizar_imagenes_por_clase(output_dir)\n",
    "dataset_final = crear_y_normalizar_dataset(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directorio con todas las imágenes organizadas por carpetas de clase.\n",
    "            transform (callable, optional): Transformaciones opcionales a aplicar a las imágenes.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Cargar las imágenes y etiquetas\n",
    "        for label, class_dir in enumerate(sorted(os.listdir(root_dir))):\n",
    "            class_dir_path = os.path.join(root_dir, class_dir)\n",
    "            for image_name in os.listdir(class_dir_path):\n",
    "                self.images.append(os.path.join(class_dir_path, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Ajusta según el tamaño de tus imágenes\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalización para modelos preentrenados\n",
    "])\n",
    "\n",
    "# Cambia 'your_data_directory' al directorio donde tienes tus imágenes organizadas\n",
    "dataset = dataset_final\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        # Ajusta la siguiente línea según el tamaño de tus imágenes después del pooling\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)  # Ajuste si tu tamaño de imagen es diferente\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 64 * 64)  # Ajuste si tu tamaño de imagen es diferente\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Asume n_classes como el número de subdirectorios/clases en tu dataset\n",
    "n_classes = len(os.listdir('c:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal/converted_images'))\n",
    "model = CNNModel(n_classes=n_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calcula la pérdida y precisión de validación después de cada época\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {100*correct/total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.6791, Val Loss: 0.7198, Val Acc: 48.26%\n",
      "Epoch 2/10, Train Loss: 0.6807, Val Loss: 0.7477, Val Acc: 46.33%\n",
      "Epoch 3/10, Train Loss: 0.6563, Val Loss: 0.7089, Val Acc: 49.81%\n",
      "Epoch 4/10, Train Loss: 0.6253, Val Loss: 0.7198, Val Acc: 53.28%\n",
      "Epoch 5/10, Train Loss: 0.5741, Val Loss: 0.7513, Val Acc: 53.28%\n",
      "Epoch 6/10, Train Loss: 0.5363, Val Loss: 0.7282, Val Acc: 52.51%\n",
      "Epoch 7/10, Train Loss: 0.4706, Val Loss: 0.7765, Val Acc: 50.58%\n",
      "Epoch 8/10, Train Loss: 0.3702, Val Loss: 0.8303, Val Acc: 52.90%\n",
      "Epoch 9/10, Train Loss: 0.2925, Val Loss: 0.9180, Val Acc: 55.60%\n",
      "Epoch 10/10, Train Loss: 0.2152, Val Loss: 1.0064, Val Acc: 53.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ruta al directorio de imágenes convertidas y organizadas\n",
    "data_directory = 'c:/Users/Matias/OneDrive/Escritorio/Tesis/Data Portugal/converted_images'\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = CustomDataset(root_dir=data_directory, transform=transform)\n",
    "\n",
    "# Dividir el dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Inicializar el modelo, pérdida y optimizador\n",
    "n_classes = len(os.listdir(data_directory))  # Asegúrate de que esto refleje el número de clases\n",
    "model = CNNModel(n_classes=n_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenar el modelo\n",
    "num_epochs = 10  # Ajusta según sea necesario\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
